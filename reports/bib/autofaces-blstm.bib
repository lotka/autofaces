Automatically generated by Mendeley Desktop 1.15.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{W??llmer2012,
abstract = {Recent studies indicate that bidirectional Long Short-Term Memory (BLSTM) recurrent neural networks are well-suited for automatic emotion recognition systems and may lead to better results than systems applying other widely used classifiers such as Support Vector Machines or feedforward Neural Networks. The good performance of BLSTM emotion recognition systems could be attributed to their ability to model and exploit contextual information self-learned via recurrently connected memory blocks which allows them to incorporate information about how emotion evolves over time. However, the actual amount of bidirectional context that a BLSTM classifier takes into account when classifying an observation has not been investigated so far. This paper presents a methodology to systematically investigate the number of past and future utterance-level observations that are considered to generate an emotion prediction for a given utterance, and to examine to what extent this temporal bidirectional context contributes to the overall BLSTM performance. Â© 2012 IEEE.},
author = {W??llmer, Martin and Metallinou, Angeliki and Katsamanis, Nassos and Schuller, Bj??rn and Narayanan, Shrikanth},
booktitle = {ICASSP, IEEE Int. Conf. Acoust. Speech Signal Process. - Proc.},
doi = {10.1109/ICASSP.2012.6288834},
file = {:homes/lm1015/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wollmer et al. - 2012 - Analyzing the memory of BLSTM Neural Networks for enhanced emotion classification in dyadic spoken interactions.pdf:pdf},
isbn = {9781467300469},
issn = {15206149},
keywords = {Long Short-Term Memory,context modeling,emotion recognition,sequential Jacobian},
month = {mar},
pages = {4157--4160},
publisher = {IEEE},
title = {{Analyzing the memory of BLSTM neural networks for enhanced emotion classification in dyadic spoken interactions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6288834},
year = {2012}
}
@article{Goel2014,
abstract = {Since the advent of deep learning, it has been used to solve various problems using many different architectures. The application of such deep architectures to auditory data is also not uncommon. However, these architectures do not always adequately consider the temporal dependencies in data. We thus propose a new generic architecture called the Deep Belief Network - Bidirectional Long Short-Term Memory (DBN-BLSTM) network that models sequences by keeping track of the temporal information while enabling deep representations in the data. We demonstrate this new architecture by applying it to the task of music generation and obtain state-of-the-art results.},
archivePrefix = {arXiv},
arxivId = {1412.6093},
author = {Goel, Kratarth and Vohra, Raunaq},
eprint = {1412.6093},
file = {:homes/lm1015/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goel, Vohra - 2014 - Learning Temporal Dependencies in Data Using a DBN-BLSTM.pdf:pdf},
month = {dec},
pages = {6},
title = {{Learning Temporal Dependencies in Data Using a DBN-BLSTM}},
url = {http://arxiv.org/abs/1412.6093},
year = {2014}
}
