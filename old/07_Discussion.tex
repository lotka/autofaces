\chapter{Discussion \& Conclusion}

  \section{Evaluation of the Method}
    These models present a very large hyperparameter space that can be
    explored, therefore it is no surprise that this project was able to explore
    a very small part of this, using existing work and experiments for guidance.

    The path taken in this project was one where a classifier network was built
    with some inspiration from the literature and then the decoder section was
    added on. The inverse approach may have given better results, which is to
    design a fully functional autoencoder and then add a classifier.

    Further it may have been instructive to fully explore what features the
    autoencoder is learning by visualising the convolutional filters and
    outputs. This is fairly time consuming and so was not included, it could be
    that the features are not directly correlated to AU's and are much more
    related to reconstructing subject related features.

    % This all sounds more like future work,
    % since you describe what you COULD have done differently
    % or in a better fashion. Before that, you should summarize
    % the conclusion that you CAN actually draw from your work.
    % This insinuates that your appoach did not contain a fully functional autoencoder. Is this the case?

    Certain things could have been improved with the preprocessing methods,
    potentially doing them before resizing the images may have improved their
    ability to expose AU features. Lots of time was also spent on these, which
    could have possibly been spent on improving the balance of that data.

    A key issue with the DISFA dataset is that many frames do not contain much
    expression information because of neutral faces. Increasing the frequency of
    the high information labels might have lead to better generalisation for the
    test data set.

    The training of the autoencoder was not stacked, instead it was joint which
    has proven to be preferable in certain situations \cite{Zhou2014}. However,
    in this case it might have been more reliable to perform stacked training of
    the autoencoder to ensure useful features were picked out.

  \section{Future Work}
    This project effectively built the neural network structures from scratch.
    An alternative approach would be to find a network in the literature which
    is pre-trained and already is very good at extracting certain features and
    use that as a base. This also might have allowed for the easier comparison
    of the results to the literature.

    Artificially increasing the size of the training set seems like a big
    priority, this would allow both the classifier and autoencoder to learn more
    general features. Some methods for doing this are as follows:

    \begin{itemize}
      \item Courrupting the input image or hidden layer representations
      \item Appyling random transformations to the input image (crops, displacements, etc.)
      \item Training the autoencoder with other datasets
    \end{itemize}

    % Using a ResNet \cite{} might have allowed larger networks with the penalty of an increased
    % nubmber of parameters.

  \section{Conclusion}
    The results have not shown that an autoencoder, in our particular setting,
    gives significant improvements to classification performance. However it has
    explored how preprocessing techniques and various neural network structures
    interact, showing that with small datasets such as DISFA other techniques
    may be more important. An unconventional part of this work, given the
    excitement in the field of deep learning is that the smaller networks
    perform better. This is most probably due to the fact that the input data
    was too homogeneous and that the task of detecting AUs is difficult, in
    particular in the way the problem was set up with even intensity one AUs
    (barely visible to humans and related to context) were included as a
    positive example. The method of per subject mean face normalisation was
    found to out perform other preprocessing methods conclusively and the
    classifier achieved competitive results on the DISFA dataset.
